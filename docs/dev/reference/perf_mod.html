<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Bayesian Analysis of Resampling Statistics — perf_mod • tidyposterior</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>

<!-- Bootstrap -->
<link href="../tidyverse.css" rel="stylesheet">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script>

<!-- sticky kit -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>
<link href="../tidyverse-2.css" rel="stylesheet">

<meta property="og:title" content="Bayesian Analysis of Resampling Statistics — perf_mod" />

<meta property="og:description" content="Bayesian analysis used here to answer the question: &quot;when
looking at resampling results, are the differences between
models 'real?'&quot; To answer this, a model can be created were the
outcome is the resampling statistics (e.g. accuracy or RMSE).
These values are explained by the model types. In doing this, we
can get parameter estimates for each model's affect on
performance and make statistical (and practical) comparisons
between models." />
<meta name="twitter:card" content="summary" />

<meta name="robots" content="noindex">

<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->

<!-- google analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-115082821-1"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());

 gtag('config', 'UA-115082821-1');
</script>
  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      <div class="navbar-brand-container">
        <a class="navbar-brand" href="../index.html">tidyposterior</a>
        <div class="info">
          <span class="partof">part of <a href="https://github.com/tidymodels">tidymodels</a></span>
          <span class="version version-danger" data-toggle="tooltip" data-placement="bottom" title="In-development version">0.0.1.9000</span>
        </div>
      </div>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="../articles/Getting_Started.html">Getting Started</a>
</li>
<li>
  <a href="../articles/Different_Bayesian_Models.html">Different Bayesian Models</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
        
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Bayesian Analysis of Resampling Statistics</h1>
    
    <div class="hidden name"><code>perf_mod.Rd</code></div>
    </div>

    <div class="ref-description">
    
    <p>Bayesian analysis used here to answer the question: "when
looking at resampling results, are the differences between
models 'real?'" To answer this, a model can be created were the
<em>outcome</em> is the resampling statistics (e.g. accuracy or RMSE).
These values are explained by the model types. In doing this, we
can get parameter estimates for each model's affect on
performance and make statistical (and practical) comparisons
between models.</p>
    
    </div>

    <pre class="usage"><span class='fu'>perf_mod</span>(<span class='no'>object</span>, <span class='no'>...</span>)

<span class='co'># S3 method for rset</span>
<span class='fu'>perf_mod</span>(<span class='no'>object</span>, <span class='kw'>transform</span> <span class='kw'>=</span> <span class='no'>no_trans</span>,
  <span class='kw'>hetero_var</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='no'>...</span>)

<span class='co'># S3 method for vfold_cv</span>
<span class='fu'>perf_mod</span>(<span class='no'>object</span>, <span class='kw'>transform</span> <span class='kw'>=</span> <span class='no'>no_trans</span>,
  <span class='kw'>hetero_var</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='no'>...</span>)

<span class='co'># S3 method for resamples</span>
<span class='fu'>perf_mod</span>(<span class='no'>object</span>, <span class='kw'>transform</span> <span class='kw'>=</span> <span class='no'>no_trans</span>,
  <span class='kw'>hetero_var</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>metric</span> <span class='kw'>=</span> <span class='no'>object</span>$<span class='no'>metrics</span>[<span class='fl'>1</span>], <span class='no'>...</span>)

<span class='co'># S3 method for data.frame</span>
<span class='fu'>perf_mod</span>(<span class='no'>object</span>, <span class='kw'>transform</span> <span class='kw'>=</span> <span class='no'>no_trans</span>,
  <span class='kw'>hetero_var</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='no'>...</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>object</th>
      <td><p>A data frame or an <code>rset</code> object (such as
<code><a href='https://www.rdocumentation.org/packages/rsample/topics/vfold_cv'>rsample::vfold_cv()</a></code>) containing the <code>id</code> column(s) and at least
two numeric columns of model performance statistics (e.g.
accuracy). Additionally, an object from <code><a href='https://www.rdocumentation.org/packages/caret/topics/resamples'>caret::resamples</a></code>
can be used.</p></td>
    </tr>
    <tr>
      <th>...</th>
      <td><p>Additonal arguments to pass to <code><a href='https://www.rdocumentation.org/packages/rstanarm/topics/stan_glmer'>rstanarm::stan_glmer()</a></code>
such as <code>verbose</code>, <code>prior</code>, <code>seed</code>, <code>family</code>, etc.</p></td>
    </tr>
    <tr>
      <th>transform</th>
      <td><p>An named list of transformation and inverse
transformation fuctions. See <code><a href='transformations.html'>logit_trans()</a></code> as an example.</p></td>
    </tr>
    <tr>
      <th>hetero_var</th>
      <td><p>A logical; if <code>TRUE</code>, then different
variances are estimated for each model group. Otherwise, the
same variance is used for each group. Estimating heterogeneous
variances may slow or prevent convergence.</p></td>
    </tr>
    <tr>
      <th>metric</th>
      <td><p>A single character value for the statstic from
the <code>resamples</code> object that should be analyzed.</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>An object of class <code>perf_mod</code>.</p>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>These functions can be used to process and analyze
matched resampling statistics from different models using a
Bayesian generalized linear model with effects for the model and
the resamples.</p>
<p>By default, a generalized linear model with Gaussian error and
an identity link is fit to the data and has terms for the
predictive model grouping variable. In this way, the performance
metrics can be compared between models.</p>
<p>Additionally, random effect terms are also used. For most
resampling methods (except repeated <em>V</em>-fold cross-validation),
a simple random intercept model its used with an exchangeable
(i.e. compound-symmetric) variance structure. In the case of
repeated cross-validation, two random intercept terms are used;
one for the repeat and another for the fold within repeat. These
also have exchangeable correlation structures.</p>
<p>The above model specification assumes that the variance in the
performance metrics is the same across models. However, this is
unlikely to be true in some cases. For example, for simple
binomial accuracy, it well know that the variance is highest
when the accuracy is near 50 percent. When the argument
<code><a href='https://www.rdocumentation.org/packages/base/topics/assignOps'>hetero_var = TRUE</a></code>, the variance structure uses random
intercepts for each model term. This may produce more realistic
posterior distributions but may take more time to converge.</p>
<p>Also, as shown in the package vignettes, the Gaussian assumption
make be unrealistic. In this case, there are at least two
approaches that can be used. First, the outcome statistics can
be transformed prior to fitting the model. For example, for
accuracy, the logit transformation can be used to convert the
outcome values to be on the real line and a model is fit to
these data. Once the posterior distributions are computed, the
inverse transformation can be used to put them back into the
original units. The <code>transform</code> argument can be used to do this.</p>
<p>The second approach would be to use a different error
distribution from the exponential family. For RMSE values, the
Gamma distribution may produce better results at the expense of
model computational complexity. This can be achieved by passing
the <code>family</code> argument to <code>perf_mod</code> as one might with the
<code>glm</code> function.</p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='co'># Example objects from the "Getting Started" vignette at</span>
<span class='co'>#  https://topepo.github.io/tidyposterior/articles/Getting_Started.html</span>

<span class='no'>file</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/system.file'>system.file</a></span>(<span class='st'>"examples"</span>, <span class='st'>"roc_model.RData"</span>, <span class='kw'>package</span> <span class='kw'>=</span> <span class='st'>"tidyposterior"</span>)
<span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/load'>load</a></span>(<span class='no'>file</span>)

<span class='no'>roc_model</span></div><div class='output co'>#&gt; Bayesian Analysis of Resampling Results
#&gt; Original data: 10-fold cross-validation using stratification
#&gt; </div><div class='input'>
<span class='co'># Summary method shows the underlying `stan` model</span>
<span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/summary'>summary</a></span>(<span class='no'>roc_model</span>)</div><div class='output co'>#&gt; 
#&gt; Model Info:
#&gt; 
#&gt;  function:     stan_glmer
#&gt;  family:       gaussian [identity]
#&gt;  formula:      statistic ~ model + (1 | id)
#&gt;  algorithm:    sampling
#&gt;  priors:       see help('prior_summary')
#&gt;  sample:       4000 (posterior sample size)
#&gt;  observations: 30
#&gt;  groups:       id (10)
#&gt; 
#&gt; Estimates:
#&gt;                                     mean   sd   2.5%   25%   50%   75%   97.5%
#&gt; (Intercept)                        0.8    0.0  0.8    0.8   0.8   0.8   0.8   
#&gt; modelknn                           0.0    0.0  0.0    0.0   0.0   0.0   0.0   
#&gt; modelnnet                          0.1    0.0  0.0    0.0   0.1   0.1   0.1   
#&gt; b[(Intercept) id:Fold01]           0.0    0.0  0.0    0.0   0.0   0.0   0.0   
#&gt; b[(Intercept) id:Fold02]           0.0    0.0  0.0    0.0   0.0   0.0   0.0   
#&gt; b[(Intercept) id:Fold03]           0.0    0.0  0.0    0.0   0.0   0.0   0.0   
#&gt; b[(Intercept) id:Fold04]           0.0    0.0  0.0    0.0   0.0   0.0   0.0   
#&gt; b[(Intercept) id:Fold05]           0.0    0.0  0.0    0.0   0.0   0.0   0.0   
#&gt; b[(Intercept) id:Fold06]           0.0    0.0  0.0    0.0   0.0   0.0   0.0   
#&gt; b[(Intercept) id:Fold07]           0.0    0.0  0.0    0.0   0.0   0.0   0.0   
#&gt; b[(Intercept) id:Fold08]           0.0    0.0  0.0    0.0   0.0   0.0   0.0   
#&gt; b[(Intercept) id:Fold09]           0.0    0.0  0.0    0.0   0.0   0.0   0.0   
#&gt; b[(Intercept) id:Fold10]           0.0    0.0  0.0    0.0   0.0   0.0   0.0   
#&gt; sigma                              0.0    0.0  0.0    0.0   0.0   0.0   0.0   
#&gt; Sigma[id:(Intercept),(Intercept)]  0.0    0.0  0.0    0.0   0.0   0.0   0.0   
#&gt; mean_PPD                           0.8    0.0  0.8    0.8   0.8   0.8   0.8   
#&gt; log-posterior                     83.9    4.3 75.0   81.0  84.1  87.1  91.4   
#&gt; 
#&gt; Diagnostics:
#&gt;                                   mcse Rhat n_eff
#&gt; (Intercept)                       0.0  1.0  2681 
#&gt; modelknn                          0.0  1.0  2970 
#&gt; modelnnet                         0.0  1.0  3314 
#&gt; b[(Intercept) id:Fold01]          0.0  1.0  4000 
#&gt; b[(Intercept) id:Fold02]          0.0  1.0  1162 
#&gt; b[(Intercept) id:Fold03]          0.0  1.0  4000 
#&gt; b[(Intercept) id:Fold04]          0.0  1.0  2008 
#&gt; b[(Intercept) id:Fold05]          0.0  1.0  4000 
#&gt; b[(Intercept) id:Fold06]          0.0  1.0  4000 
#&gt; b[(Intercept) id:Fold07]          0.0  1.0  3259 
#&gt; b[(Intercept) id:Fold08]          0.0  1.0  1952 
#&gt; b[(Intercept) id:Fold09]          0.0  1.0  2016 
#&gt; b[(Intercept) id:Fold10]          0.0  1.0  3219 
#&gt; sigma                             0.0  1.0  1390 
#&gt; Sigma[id:(Intercept),(Intercept)] 0.0  1.0  1342 
#&gt; mean_PPD                          0.0  1.0  4000 
#&gt; log-posterior                     0.2  1.0   688 
#&gt; 
#&gt; For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#value">Value</a></li>

      <li><a href="#details">Details</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

  </div>
</div>

      <footer>
      <div class="tidyverse">
  <p><code>tidyposterior</code> is a part of the <strong>tidymodels</strong> ecosystem, a collection of modeling packages designed with common APIs and a shared philosophy.</p>
</div>

<div class="author">
  <p>
    Developed by Max Kuhn.
    Site built by <a href="https://pkgdown.r-lib.org">pkgdown</a>.
  </p>
</div>
      </footer>
   </div>

  

  </body>
</html>

